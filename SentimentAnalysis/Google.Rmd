---
title: "Google"
author: "Ray Flores"
date: "October 9, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(syuzhet)
library(wordcloud)
library(ggplot2)
library(MASS)
library(pastecs)
library(shiny)
library(shinydashboard)
library(ggthemes)
library(tidytext)
library(tidyverse)
library(tm)
library(lubridate)
library(stringr)
library(reader)
library(csvread)
library(twitteR)
library(devtools)
#if(!require(Rstem)) install_url("http://cran.r-project.org/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz")
#if(!require(sentiment)) install_url("http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz")
#library(Rstem)
#library(sentiment)
library(plotly)
library(dplyr)
library(Quandl)
library(magrittr)
library(tseries)


### Essential Companies
amazon <- read.csv(file="Amazon.csv",head=TRUE,sep=",")
apple <- read.csv(file="Apple.csv",head=TRUE,sep=",")
boeing <- read.csv(file="Boeing.csv",head=TRUE,sep=",")
facebook <- read.csv(file="Facebook.csv",head=TRUE,sep=",")
ford <- read.csv(file="Ford.csv",head=TRUE,sep=",")
google <- read.csv(file="Google.csv",head=TRUE,sep=",")
macys <- read.csv(file="Macy's.csv",head=TRUE,sep=",")
newYorkTimes <- read.csv(file="NewYorkTimes.csv", head=TRUE,sep=",")

# google_text <- subset(google, select=c("text"))
# class(google)

google_text <- as.character(google[["text"]])


# Function for cleaning tweets
cleanTweets <- function (tweets) {
  
  
  #sapply(tweets, function(x) x$$getText())
  
  
  clean_tweets = as.character(tweets[[2]])
  # remove retweet entities
  clean_tweets = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', clean_tweets)
  # remove @people
  clean_tweets = gsub('@\\w+', '', clean_tweets)
  # remove punctuation
  clean_tweets = gsub('[[:punct:]]', '', clean_tweets)
  # remove numbers
  clean_tweets = gsub('[[:digit:]]', '', clean_tweets)
  # remove html links
  clean_tweets = gsub('http\\w+', '', clean_tweets)
  # remove unnecessary spaces
  #clean_tweets = gsub('[ \t]{2,}', '', clean_tweets)
  #clean_tweets = gsub('^\\s+|\\s+$', '', clean_tweets)
  # remove emojis or special characters
  clean_tweets = gsub('<.*>', '', enc2native(clean_tweets))
  
  clean_tweets = tolower(clean_tweets)
  
  clean_tweets
}

get_time_stamp <- function (tweets) {
  
  tweets_time = as.character(tweets[[3]])
  clean_time = as.POSIXct(tweets_time, tz = "GMT", origin="1970-01-01", format = "%D %k ")
  clean_time
  
}

### Vector of company names, if needed available
companies <- factor(c("Amazon", "google", "Google", "google", "google", "Ford"))

### Use the function defined above to clean the tweets by the president 
### and separate according to columns 

### Company tweets
#amazonTweets <- cleanTweets(amazon["text"])

googleTweets <- cleanTweets(google)

# Amazon
# amazonTimeStamp <- as.POSIXct(sapply(amazon["created_at"], 
#                                      function(x)x$getCreated()), 
#                                         origin="1970-01-01", tz="GMT")

googleTimeStamp <- get_time_stamp(google)
googleTimeStamp <- googleTimeStamp[!duplicated(google["text"])]
googleTweets <- googleTweets[!duplicated(google["text"])]




# google
googleSyuzhet <- get_sentiment(googleTweets, method="syuzhet")
googleBing <- get_sentiment(googleTweets, method="bing")
googleAfinn <- get_sentiment(googleTweets, method="afinn")
googleNrc <- get_sentiment(googleTweets, method="nrc")
googleSentiments <- data.frame(googleSyuzhet, googleBing, googleAfinn, googleNrc, googleTimeStamp)






# google
googleEmotions <- get_nrc_sentiment(googleTweets)
googleEmoBar = colSums(googleEmotions)
googleEmoSum = data.frame(count=googleEmoBar, emotion=names(googleEmoBar))
googleEmoSum$emotion = factor(googleEmoSum$emotion, levels=googleEmoSum$emotion[order(googleEmoSum$count, decreasing = TRUE)])




# google
plot_ly(googleSentiments, x=~googleTimeStamp, y=~googleSyuzhet, type="scatter", mode="jitter", name="syuzhet") %>%
  add_trace(y=~googleBing, mode="lines", name="bing") %>%
  add_trace(y=~googleAfinn, mode="lines", name="afinn") %>%
  add_trace(y=~googleNrc, mode="lines", name="nrc") %>%
  layout(title="Trump Twitter Sentiment for Company google",
         yaxis=list(title="score"), xaxis=list(title="date"))



# google
plot_ly(googleEmoSum, x=~emotion, y=~count, type="bar", color=~emotion) %>%
  layout(xaxis=list(title="Emotions"), yaxis=list(title="Count"), showlegend=FALSE,
         title="Distribution of Emotion for Google Related Trump Tweets")


# google
googleAll = c(
  paste(googleTweets[googleEmotions$anger > 0], collapse=" "),
  paste(googleTweets[googleEmotions$anticipation > 0], collapse=" "),
  paste(googleTweets[googleEmotions$disgust > 0], collapse=" "),
  paste(googleTweets[googleEmotions$fear > 0], collapse=" "),
  paste(googleTweets[googleEmotions$joy > 0], collapse=" "),
  paste(googleTweets[googleEmotions$sadness > 0], collapse=" "),
  paste(googleTweets[googleEmotions$surprise > 0], collapse=" "),
  paste(googleTweets[googleEmotions$trust > 0], collapse=" ")
)
googleAll <- removeWords(googleAll, stopwords("english"))



# google
googleCorpus = Corpus(VectorSource(googleAll))


# google
googleTdm = TermDocumentMatrix(googleCorpus)



# google
googleTdm = as.matrix(googleTdm)
googleTdm1 <- googleTdm[nchar(rownames(googleTdm)) < 11,]


# google
colnames(googleTdm) = c('anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust')
colnames(googleTdm1) <- colnames(googleTdm)



# google
comparison.cloud(googleTdm1, random.order=FALSE,
                 colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"),
                 title.size=1, max.words=1000, scale=c(3.5, 0.1),rot.per=0.4)


```